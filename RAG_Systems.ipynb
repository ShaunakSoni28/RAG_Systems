{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaunakSoni28/RAG_Systems/blob/main/RAG_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Creating project directory structure\n",
        "import os\n",
        "project_dir = '/content/drive/MyDrive/RAG_Project/'\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/papers', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/data', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/results', exist_ok=True)\n",
        "os.makedirs(f'{project_dir}/evaluation', exist_ok=True)\n",
        "\n",
        "print(f\"✅ Project directory: {project_dir}\")\n",
        "print(\"✅ All work will be saved to Google Drive!\")\n",
        "print(\"✅ Safe from disconnects!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qBp4ViAghFW",
        "outputId": "371799fe-7bdb-4f15-8a28-f39c3beb5151"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Project directory: /content/drive/MyDrive/RAG_Project/\n",
            "✅ All work will be saved to Google Drive!\n",
            "✅ Safe from disconnects!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIXjDohCR7jc",
        "outputId": "f009c0d0-4bd0-42c4-f88d-9707eae1cbc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.12/dist-packages (2.2.0)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.12/dist-packages (from arxiv) (6.0.12)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.12/dist-packages (from arxiv) (2.32.4)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (2025.10.5)\n",
            "✅ Setup complete!\n",
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "# Installing required libraries\n",
        "!pip install -q transformers accelerate sentence-transformers faiss-cpu pypdf langchain huggingface_hub\n",
        "\n",
        "# Downloading papers directly in Colab\n",
        "!pip install arxiv\n",
        "\n",
        "\n",
        "# Importing basic libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import arxiv\n",
        "\n",
        "print(\"✅ Setup complete!\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "project_dir = '/content/drive/MyDrive/RAG_Project/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wic1eb4zSNpt",
        "outputId": "9239ce42-6218-4b7a-9e0a-d84791e9abd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3006221215.py:15: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in search.results():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Downloaded 50 papers!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import arxiv\n",
        "import os\n",
        "\n",
        "# Creating the directory if it doesn't exist\n",
        "os.makedirs(\"/content/drive/MyDrive/RAG_Project/papers\", exist_ok=True)\n",
        "\n",
        "# Searching for NLP papers\n",
        "search = arxiv.Search(\n",
        "    query=\"cat:cs.CL\",  # Computer Science - Computation and Language\n",
        "    max_results=50,\n",
        "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
        ")\n",
        "\n",
        "papers = []\n",
        "for result in search.results():\n",
        "    papers.append({\n",
        "        'title': result.title,\n",
        "        'pdf_url': result.pdf_url,\n",
        "        'summary': result.summary,\n",
        "        'authors': [author.name for author in result.authors]\n",
        "    })\n",
        "    # Downloading PDF\n",
        "    result.download_pdf(filename=f\"/content/drive/MyDrive/RAG_Project/papers/{result.get_short_id()}.pdf\")\n",
        "\n",
        "print(f\"✅ Downloaded {len(papers)} papers!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyPDF2\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "  try:\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text=\"\"\n",
        "    for page in reader.pages:\n",
        "      text += page.extract_text() + \"\\n\"\n",
        "    return text.strip()\n",
        "  except Exception as e:\n",
        "    print(f\"Error with {pdf_path}: {e}\")\n",
        "    return \"\"\n",
        "\n",
        "print(\"\\n Processing 50 Downloaded Papers!\")\n",
        "all_papers=[]\n",
        "\n",
        "paper_files = [f for f in os.listdir(f\"{project_dir}papers/\") if f.endswith(\".pdf\") and not f.startswith(\"distractor_\")]\n",
        "\n",
        "for pdf_file in tqdm(paper_files, desc=\"Processing PDFs\"):\n",
        "  pdf_path = f\"{project_dir}/papers/{pdf_file}\"\n",
        "  text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "  if text and len(text.split()) > 100:\n",
        "    all_papers.append({\n",
        "        'filename ' : pdf_file,\n",
        "        'text' : text,\n",
        "        'word_count' : len(text.split()),\n",
        "        'is_distractor' : False\n",
        "    })\n",
        "\n",
        "    print(f\"Succesfuly processed {len(all_papers)} papers!\")\n",
        "    print(f\"Avergae words per paper: {sum(p['word_count'] for p in all_papers)//len(all_papers)}\")\n",
        "\n",
        "    # Saving the files in the drive\n",
        "\n",
        "    with open(f'{project_dir}data/main_papers.pkl','wb') as f:\n",
        "      pickle.dump(all_papers,f)\n",
        "    print(f\"Saved in Google Drive: {project_dir}data/main_papers.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nua4MWijofD",
        "outputId": "7487f255-9753-4bc2-8da0-397d2f57c48e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Processing 50 Downloaded Papers!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs:   2%|▏         | 1/50 [00:00<00:05,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 1 papers!\n",
            "Avergae words per paper: 3368\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:   4%|▍         | 2/50 [00:00<00:07,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 2 papers!\n",
            "Avergae words per paper: 4431\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:   6%|▌         | 3/50 [00:00<00:12,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 3 papers!\n",
            "Avergae words per paper: 6136\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:   8%|▊         | 4/50 [00:02<00:34,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 4 papers!\n",
            "Avergae words per paper: 9496\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n",
            "Succesfuly processed 5 papers!\n",
            "Avergae words per paper: 9169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  10%|█         | 5/50 [00:02<00:24,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  12%|█▏        | 6/50 [00:02<00:20,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 6 papers!\n",
            "Avergae words per paper: 8874\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs:  16%|█▌        | 8/50 [00:03<00:12,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 7 papers!\n",
            "Avergae words per paper: 7973\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n",
            "Succesfuly processed 8 papers!\n",
            "Avergae words per paper: 7632\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  18%|█▊        | 9/50 [00:03<00:15,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 9 papers!\n",
            "Avergae words per paper: 8519\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  20%|██        | 10/50 [00:03<00:13,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 10 papers!\n",
            "Avergae words per paper: 8407\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  22%|██▏       | 11/50 [00:04<00:14,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 11 papers!\n",
            "Avergae words per paper: 8446\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  24%|██▍       | 12/50 [00:05<00:19,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 12 papers!\n",
            "Avergae words per paper: 8500\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  26%|██▌       | 13/50 [00:06<00:29,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 13 papers!\n",
            "Avergae words per paper: 9037\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs:  30%|███       | 15/50 [00:07<00:19,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 14 papers!\n",
            "Avergae words per paper: 8901\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n",
            "Succesfuly processed 15 papers!\n",
            "Avergae words per paper: 8673\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs:  34%|███▍      | 17/50 [00:07<00:11,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 16 papers!\n",
            "Avergae words per paper: 8580\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n",
            "Succesfuly processed 17 papers!\n",
            "Avergae words per paper: 8324\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  36%|███▌      | 18/50 [00:09<00:22,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 18 papers!\n",
            "Avergae words per paper: 9710\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  38%|███▊      | 19/50 [00:09<00:17,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 19 papers!\n",
            "Avergae words per paper: 9563\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  40%|████      | 20/50 [00:16<01:16,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 20 papers!\n",
            "Avergae words per paper: 9859\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  42%|████▏     | 21/50 [00:16<00:54,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 21 papers!\n",
            "Avergae words per paper: 9761\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  44%|████▍     | 22/50 [00:17<00:40,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 22 papers!\n",
            "Avergae words per paper: 9786\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs:  48%|████▊     | 24/50 [00:18<00:26,  1.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 23 papers!\n",
            "Avergae words per paper: 9734\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n",
            "Succesfuly processed 24 papers!\n",
            "Avergae words per paper: 9591\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  50%|█████     | 25/50 [00:19<00:21,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 25 papers!\n",
            "Avergae words per paper: 9520\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs:  54%|█████▍    | 27/50 [00:19<00:12,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 26 papers!\n",
            "Avergae words per paper: 9267\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n",
            "Succesfuly processed 27 papers!\n",
            "Avergae words per paper: 9150\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  56%|█████▌    | 28/50 [00:20<00:11,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 28 papers!\n",
            "Avergae words per paper: 9238\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  58%|█████▊    | 29/50 [00:21<00:13,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 29 papers!\n",
            "Avergae words per paper: 9135\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  60%|██████    | 30/50 [00:22<00:15,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 30 papers!\n",
            "Avergae words per paper: 9479\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  62%|██████▏   | 31/50 [00:22<00:12,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 31 papers!\n",
            "Avergae words per paper: 9467\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  64%|██████▍   | 32/50 [00:22<00:09,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 32 papers!\n",
            "Avergae words per paper: 9386\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  66%|██████▌   | 33/50 [00:27<00:29,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 33 papers!\n",
            "Avergae words per paper: 9461\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  68%|██████▊   | 34/50 [00:28<00:24,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 34 papers!\n",
            "Avergae words per paper: 9580\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  70%|███████   | 35/50 [00:29<00:20,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 35 papers!\n",
            "Avergae words per paper: 9578\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  72%|███████▏  | 36/50 [00:29<00:14,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 36 papers!\n",
            "Avergae words per paper: 9516\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  74%|███████▍  | 37/50 [00:29<00:11,  1.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 37 papers!\n",
            "Avergae words per paper: 9458\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  76%|███████▌  | 38/50 [00:30<00:08,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 38 papers!\n",
            "Avergae words per paper: 9400\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  78%|███████▊  | 39/50 [00:31<00:08,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 39 papers!\n",
            "Avergae words per paper: 9486\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  80%|████████  | 40/50 [00:31<00:07,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 40 papers!\n",
            "Avergae words per paper: 9604\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  82%|████████▏ | 41/50 [00:33<00:07,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 41 papers!\n",
            "Avergae words per paper: 9636\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  84%|████████▍ | 42/50 [00:34<00:08,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 42 papers!\n",
            "Avergae words per paper: 9597\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  86%|████████▌ | 43/50 [00:35<00:07,  1.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 43 papers!\n",
            "Avergae words per paper: 9567\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  88%|████████▊ | 44/50 [00:37<00:06,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 44 papers!\n",
            "Avergae words per paper: 9802\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  90%|█████████ | 45/50 [00:38<00:05,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 45 papers!\n",
            "Avergae words per paper: 9747\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  92%|█████████▏| 46/50 [00:38<00:03,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 46 papers!\n",
            "Avergae words per paper: 9786\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs:  96%|█████████▌| 48/50 [00:39<00:01,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 47 papers!\n",
            "Avergae words per paper: 9852\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n",
            "Succesfuly processed 48 papers!\n",
            "Avergae words per paper: 9793\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing PDFs:  98%|█████████▊| 49/50 [00:39<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 49 papers!\n",
            "Avergae words per paper: 9662\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing PDFs: 100%|██████████| 50/50 [00:41<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfuly processed 50 papers!\n",
            "Avergae words per paper: 9812\n",
            "Saved in Google Drive: /content/drive/MyDrive/RAG_Project/data/main_papers.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading 100 distractor papers from broader AI topics...\")\n",
        "\n",
        "# Distractor Papers\n",
        "\n",
        "distractor_queries=[\n",
        "    \"cat:cs.AI\", # Artificial Intelligence\n",
        "    \"cat:cs.LG\", # Machine Learning\n",
        "    \"cat:cs.CV\", # Computer Vision\n",
        "]\n",
        "\n",
        "distractor_count = 0\n",
        "\n",
        "target_distractor = 100\n",
        "downloads_ids = set() # creating a set that will help to store the ids of the distractor sequenctially\n",
        "\n",
        "for query in distractor_queries:\n",
        "  if distractor_count >= target_distractor:\n",
        "    break\n",
        "\n",
        "  print(\"Searching...\")\n",
        "\n",
        "  search = arxiv.Search(\n",
        "      query = query ,\n",
        "      max_results = 40 ,\n",
        "      sort_by = arxiv.SortCriterion.SubmittedDate, # Here we are sorthing the data according to the publishing/submitting date\n",
        "  )\n",
        "\n",
        "  for result in search.results():\n",
        "    if distractor_count >= target_distractor:\n",
        "      break\n",
        "\n",
        "    paper_id = result.get_short_id() # getting the paper id\n",
        "\n",
        "    if paper_id == downloads_ids: # If the paper is downloaded then skip it\n",
        "      continue\n",
        "\n",
        "    try:\n",
        "      filename = f\"/content/drive/MyDrive/RAG_Project/papers/distractor_{paper_id}.pdf\"\n",
        "\n",
        "      if os.path.exists(filename):\n",
        "        distractor_count += 1\n",
        "        downloads_ids.add(paper_id)\n",
        "        continue\n",
        "\n",
        "      result.download_pdf(filename = filename)\n",
        "      downloads_ids.add(paper_id)\n",
        "      distractor_count +=1\n",
        "\n",
        "      if distractor_count % 10 == 0 :\n",
        "        print(f\"Downloaded {distractor_count}/{target_distractor}\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Failed to download {paper_id}: {e}\")\n",
        "      continue\n",
        "\n",
        "    print(f\"Total paper downloaded {distractor_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H79UNytxo_uH",
        "outputId": "9032f692-359c-4969-86bc-7fc8b195b54e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 100 distractor papers from broader AI topics...\n",
            "Searching...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2725989359.py:28: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in search.results():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching...\n",
            "Searching...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd4mWKEGSdu1",
        "outputId": "22f2f916-ea90-45bf-cb81-0fd07f72e1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embedding model...\n",
            "✅ Embedding model loaded!\n",
            "✅ Created 5 chunks\n",
            "Sample chunk 1: Attention mechanisms have become integral to sequence modeling tasks in natural language processing....\n",
            "Sample chunk 2: recurrent or convolutional layers. BERT uses bidirectional transformers for language understanding a...\n",
            "\n",
            "Creating embeddings...\n",
            "✅ Embeddings shape: (5, 384)\n",
            "✅ FAISS index created with 5 vectors\n",
            "\n",
            "============================================================\n",
            "✅ RETRIEVAL TEST\n",
            "============================================================\n",
            "Query: What are attention mechanisms?\n",
            "\n",
            "1. Distance: 0.9611\n",
            "   Chunk: Attention mechanisms have become integral to sequence modeling tasks in natural language processing. The Transformer architecture, introduced in the p...\n",
            "\n",
            "2. Distance: 1.3043\n",
            "   Chunk: impressive performance on various downstream tasks through fine-tuning or few-shot learning. Recent work has focused on making transformers more effic...\n",
            "\n",
            "3. Distance: 1.3635\n",
            "   Chunk: recurrent or convolutional layers. BERT uses bidirectional transformers for language understanding and has achieved state-of-the-art results on many N...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. SETUP: Load embedding model\n",
        "print(\"Loading embedding model...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"✅ Embedding model loaded!\")\n",
        "\n",
        "# 2. PREPARE: Chunk your documents\n",
        "def chunk_text(text, chunk_size=500, overlap=50):\n",
        "    \"\"\"Split text into overlapping chunks\"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk = ' '.join(words[i:i + chunk_size])\n",
        "        if chunk.strip():  # Only add non-empty chunks\n",
        "            chunks.append(chunk)\n",
        "\n",
        "    # If no chunks created (text too short), use the whole text\n",
        "    if len(chunks) == 0:\n",
        "        chunks = [text.strip()]\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Example with one paper - LONGER sample text\n",
        "sample_text = \"\"\"\n",
        "Attention mechanisms have become integral to sequence modeling tasks in natural language processing.\n",
        "The Transformer architecture, introduced in the paper Attention is All You Need, relies entirely on self-attention mechanisms\n",
        "to compute representations of input and output sequences without using recurrent or convolutional layers.\n",
        "BERT uses bidirectional transformers for language understanding and has achieved state-of-the-art results on many NLP benchmarks.\n",
        "The key innovation of transformers is the multi-head attention mechanism which allows the model to jointly attend to information\n",
        "from different representation subspaces at different positions. This enables the model to capture long-range dependencies more\n",
        "effectively than traditional RNNs or LSTMs. GPT models use a decoder-only transformer architecture and are trained using\n",
        "a language modeling objective. These models have shown impressive performance on various downstream tasks through fine-tuning\n",
        "or few-shot learning. Recent work has focused on making transformers more efficient through techniques like sparse attention,\n",
        "linear attention mechanisms, and improved positional encodings. The scalability of transformers has enabled training of very\n",
        "large language models with billions of parameters that demonstrate emergent capabilities on complex reasoning tasks.\n",
        "\"\"\"\n",
        "\n",
        "# Use smaller chunk size for this demo\n",
        "chunks = chunk_text(sample_text, chunk_size=50, overlap=10)\n",
        "print(f\"✅ Created {len(chunks)} chunks\")\n",
        "print(f\"Sample chunk 1: {chunks[0][:100]}...\")\n",
        "if len(chunks) > 1:\n",
        "    print(f\"Sample chunk 2: {chunks[1][:100]}...\")\n",
        "\n",
        "# 3. INDEX: Create FAISS vector database\n",
        "print(\"\\nCreating embeddings...\")\n",
        "chunk_embeddings = embedding_model.encode(chunks)\n",
        "print(f\"✅ Embeddings shape: {chunk_embeddings.shape}\")\n",
        "\n",
        "# Build FAISS index\n",
        "dimension = chunk_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(chunk_embeddings)\n",
        "print(f\"✅ FAISS index created with {index.ntotal} vectors\")\n",
        "\n",
        "# 4. RETRIEVE: Search function\n",
        "def retrieve_relevant_chunks(query, top_k=3):\n",
        "    \"\"\"Retrieve most relevant chunks for a query\"\"\"\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "\n",
        "    # Make sure we don't ask for more chunks than we have\n",
        "    top_k = min(top_k, len(chunks))\n",
        "\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    results = []\n",
        "    for idx, dist in zip(indices[0], distances[0]):\n",
        "        results.append({\n",
        "            'chunk': chunks[idx],\n",
        "            'distance': float(dist),\n",
        "            'chunk_id': int(idx)\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test retrieval\n",
        "test_query = \"What are attention mechanisms?\"\n",
        "results = retrieve_relevant_chunks(test_query, top_k=3)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"✅ RETRIEVAL TEST\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"{i}. Distance: {result['distance']:.4f}\")\n",
        "    print(f\"   Chunk: {result['chunk'][:150]}...\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. GENERATE: Use Flan-T5 (works immediately, no authentication needed)\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"Loading Flan-T5 model...\")\n",
        "generator = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "print(\"✅ Flan-T5 loaded!\")\n",
        "\n",
        "def generate_answer(query, retrieved_chunks):\n",
        "    \"\"\"Generate answer using retrieved context\"\"\"\n",
        "\n",
        "    # Combine retrieved chunks into context\n",
        "    context = \"\\n\\n\".join([chunk['chunk'] for chunk in retrieved_chunks])\n",
        "\n",
        "    # Create prompt - Flan-T5 uses simpler format\n",
        "    prompt = f\"\"\"Answer the question based on the context below.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Generate\n",
        "    response = generator(\n",
        "        prompt,\n",
        "        max_length=256,\n",
        "        temperature=0.7,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    return response[0]['generated_text']\n",
        "\n",
        "# Test the full pipeline\n",
        "test_query = \"What are attention mechanisms?\"\n",
        "print(f\"\\n🔍 Query: {test_query}\")\n",
        "\n",
        "# Retrieve\n",
        "retrieved = retrieve_relevant_chunks(test_query, top_k=3)\n",
        "print(f\"\\n📚 Retrieved {len(retrieved)} chunks\")\n",
        "\n",
        "# Generate\n",
        "answer = generate_answer(test_query, retrieved)\n",
        "print(f\"\\n💡 Answer: {answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VksrwsqjYscc",
        "outputId": "719d1b4f-a6df-4d8f-fa07-d60248ad6d09"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Flan-T5 model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Flan-T5 loaded!\n",
            "\n",
            "🔍 Query: What are attention mechanisms?\n",
            "\n",
            "📚 Retrieved 3 chunks\n",
            "\n",
            "💡 Answer: to compute representations of input and output sequences without using recurrent or convolutional layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPLETE DEMO FUNCTION\n",
        "def rag_qa_system(question):\n",
        "    \"\"\"Complete RAG QA pipeline\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(f\"QUESTION: {question}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Step 1: Retrieve\n",
        "    print(\"\\n🔍 RETRIEVING relevant documents...\")\n",
        "    retrieved_chunks = retrieve_relevant_chunks(question, top_k=3)\n",
        "\n",
        "    for i, chunk in enumerate(retrieved_chunks, 1):\n",
        "        print(f\"\\n  [{i}] Similarity: {1/(1+chunk['distance']):.3f}\")\n",
        "        print(f\"      {chunk['chunk'][:100]}...\")\n",
        "\n",
        "    # Step 2: Generate\n",
        "    print(\"\\n\\n💭 GENERATING answer...\")\n",
        "    answer = generate_answer(question, retrieved_chunks)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ANSWER:\")\n",
        "    print(\"=\"*60)\n",
        "    print(answer)\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Demo questions\n",
        "demo_questions = [\n",
        "    \"What are attention mechanisms in transformers?\",\n",
        "    \"How does BERT work?\",\n",
        "    \"What is the difference between GPT and BERT?\"\n",
        "]\n",
        "\n",
        "for q in demo_questions:\n",
        "    rag_qa_system(q)\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "5EfYQt8hZK1w",
        "outputId": "92c074d8-add4-4f22-d88f-be4907a057b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "QUESTION: What are attention mechanisms in transformers?\n",
            "============================================================\n",
            "\n",
            "🔍 RETRIEVING relevant documents...\n",
            "\n",
            "  [1] Similarity: 0.532\n",
            "      Attention mechanisms have become integral to sequence modeling tasks in natural language processing....\n",
            "\n",
            "  [2] Similarity: 0.500\n",
            "      impressive performance on various downstream tasks through fine-tuning or few-shot learning. Recent ...\n",
            "\n",
            "  [3] Similarity: 0.455\n",
            "      recurrent or convolutional layers. BERT uses bidirectional transformers for language understanding a...\n",
            "\n",
            "\n",
            "💭 GENERATING answer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ANSWER:\n",
            "============================================================\n",
            "self-attention mechanisms to compute representations of input and output sequences without using recurrent or convolutional layers\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "QUESTION: How does BERT work?\n",
            "============================================================\n",
            "\n",
            "🔍 RETRIEVING relevant documents...\n",
            "\n",
            "  [1] Similarity: 0.515\n",
            "      recurrent or convolutional layers. BERT uses bidirectional transformers for language understanding a...\n",
            "\n",
            "  [2] Similarity: 0.487\n",
            "      Attention mechanisms have become integral to sequence modeling tasks in natural language processing....\n",
            "\n",
            "  [3] Similarity: 0.398\n",
            "      very large language models with billions of parameters that demonstrate emergent capabilities on com...\n",
            "\n",
            "\n",
            "💭 GENERATING answer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=256) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ANSWER:\n",
            "============================================================\n",
            "BERT uses bidirectional transformers for language understanding and has achieved state-of-the-art results on many NLP benchmarks\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "QUESTION: What is the difference between GPT and BERT?\n",
            "============================================================\n",
            "\n",
            "🔍 RETRIEVING relevant documents...\n",
            "\n",
            "  [1] Similarity: 0.457\n",
            "      different representation subspaces at different positions. This enables the model to capture long-ra...\n",
            "\n",
            "  [2] Similarity: 0.431\n",
            "      recurrent or convolutional layers. BERT uses bidirectional transformers for language understanding a...\n",
            "\n",
            "  [3] Similarity: 0.411\n",
            "      Attention mechanisms have become integral to sequence modeling tasks in natural language processing....\n",
            "\n",
            "\n",
            "💭 GENERATING answer...\n",
            "\n",
            "============================================================\n",
            "ANSWER:\n",
            "============================================================\n",
            "GPT models use a decoder-only transformer architecture and are trained using a language modeling objective\n",
            "============================================================\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNI7ebQYNWqJWULQ9u6y5lf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}